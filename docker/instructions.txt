##################################################################
# Composition
##################################################################

4 containers :

    - mongodb
        * Données dynamiques base de données MongoDB

    - mysql
        * Données statiques base de données MySQL

    - Airflow
        * Appels aux API 
            * OpenSky : toutes les 5 min
            * Airlabs : toutes les heures
        * Opérations sur les data :
            * Insert des data statistiques à l'initialisation de la base de données
            * Aggrégation 1 fois par jour des données
            * suppression des données de plus de 7 jours

    - dash
        * dashbord de l'application


##################################################################
# Structure des fichiers à respecter
##################################################################

    │   .dockerignore
    │   .env
    │   docker-compose.yaml
    |   my_dag.py
    │   setup.sh
    |
    ├───functions
    │   clean_mongodb.py
    │   connection_mongodb.py
    │   cron_airlabs.py
    │   cron_opensky.py
    │   init_mongo.py
    │   pipeline_aggregate.py
    │   utilities_live_api.py
    |
    ├───data_statistics
    │       data.json
    │
    ├───init_mongodb
    |       mongo-init.js
    │
    └───logs_test_api


##################################################################
# Fichier .env.example
##################################################################

Présence d'un fichier d'exemple pour définir votre fichier .env

    * ensemble des variables d'environnement à définir OBLIGATOIREMENT
    * modifier les valeurs illustratives par les valeur réelles
    * renommer le fichier en .env


##################################################################
# Usage
##################################################################

* Se placer dans le dossier où se trouve le docker-compose.yaml

* Lancer la commande suivante pour lancer le script automatiquement :
  ATTENTION : cela supprimera les containers, images et volumes présents sur votre machine
    
    sh ./setup.sh 

Ce script : 

    * va créer les différents dossiers nécessaires à l'installation d'airflow
        - le dossier airflow
        - les sous dossiers airflow/dags, airflow/logs et airflow/plugins

    * va copier :
        - le dossier functions dans le dosssier airflow 
        - le fichier my_dag.py dans le dossier airflow/dags/

Si vous préférez lancer les containers manuellement, vérifier dans le setup.sh
toutes les étapes à respecter

* Accès au Dashbord et à l'API:
    localhost:8050

* Accès à l'interface graphique d'airflow pour gérer vos DAG :
    localhost:8080  
